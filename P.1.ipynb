{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "\n",
    "# from keras.utils import FeatureSpace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nForcasting forest cover type from cartographic variables\\nelevational value is a important feature \\n\\n\\n\\n'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Forcasting forest cover type from cartographic variables\n",
    "elevational value is a important feature \n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('covtype.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_columns',None)\n",
    "# df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorizing samples\n",
    "test_dataframe=df.sample(frac=0.2,random_state=43)\n",
    "df_train_val=df.drop(test_dataframe.index)\n",
    "val_dataframe=df_train_val.sample(frac=0.2,random_state=85)\n",
    "train_dataframe=df_train_val.drop(val_dataframe.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def dataframe_to_dataset(dataframe):\n",
    "#     dataframe=dataframe.copy()\n",
    "#     Cover_Type=dataframe.pop('Cover_Type')\n",
    "#     ds = tf.data.Dataset.from_tensor_slices((dict(dataframe),Cover_Type))\n",
    "#     ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "#     return ds\n",
    "# test_ds = dataframe_to_dataset(test_dataframe)\n",
    "# val_ds = dataframe_to_dataset(val_dataframe)\n",
    "# train_ds = dataframe_to_dataset(val_dataframe)\n",
    "\n",
    "# feature_space = tf.keras.utils.FeatureSpace(\n",
    "#     features={\n",
    "#         # The features should be categorical\n",
    "#         \"Wilderness_Area1\": \"integer_categorical\",\n",
    "#         \"Wilderness_Area2\": \"integer_categorical\",\n",
    "#         \"Wilderness_Area3\": \"integer_categorical\",\n",
    "#         \"Wilderness_Area4\": \"integer_categorical\",\n",
    "#         \"Soil_Type1\": \"integer_categorical\",\n",
    "#         \"Soil_Type2\": \"integer_categorical\",\n",
    "#         \"Soil_Type3\": \"integer_categorical\",\n",
    "#         \"Soil_Type4\": \"integer_categorical\",\n",
    "#         \"Soil_Type5\": \"integer_categorical\",\n",
    "#         \"Soil_Type6\": \"integer_categorical\",\n",
    "#         \"Soil_Type7\": \"integer_categorical\",\n",
    "#         \"Soil_Type8\": \"integer_categorical\",\n",
    "#         \"Soil_Type9\": \"integer_categorical\",\n",
    "#         \"Soil_Type10\": \"integer_categorical\",\n",
    "#         \"Soil_Type11\": \"integer_categorical\",\n",
    "#         \"Soil_Type12\": \"integer_categorical\",\n",
    "#         \"Soil_Type13\": \"integer_categorical\",\n",
    "#         \"Soil_Type14\": \"integer_categorical\",\n",
    "#         \"Soil_Type15\": \"integer_categorical\",\n",
    "#         \"Soil_Type16\": \"integer_categorical\",\n",
    "#         \"Soil_Type17\": \"integer_categorical\",\n",
    "#         \"Soil_Type18\": \"integer_categorical\",\n",
    "#         \"Soil_Type19\": \"integer_categorical\",\n",
    "#         \"Soil_Type20\": \"integer_categorical\",\n",
    "#         \"Soil_Type21\": \"integer_categorical\",\n",
    "#         \"Soil_Type22\": \"integer_categorical\",\n",
    "#         \"Soil_Type23\": \"integer_categorical\",\n",
    "#         \"Soil_Type24\": \"integer_categorical\",\n",
    "#         \"Soil_Type25\": \"integer_categorical\",\n",
    "#         \"Soil_Type26\": \"integer_categorical\",\n",
    "#         \"Soil_Type27\": \"integer_categorical\",\n",
    "#         \"Soil_Type28\": \"integer_categorical\",\n",
    "#         \"Soil_Type29\": \"integer_categorical\",\n",
    "#         \"Soil_Type30\": \"integer_categorical\",\n",
    "#         \"Soil_Type31\": \"integer_categorical\",\n",
    "#         \"Soil_Type32\": \"integer_categorical\",\n",
    "#         \"Soil_Type33\": \"integer_categorical\",\n",
    "#         \"Soil_Type34\": \"integer_categorical\",\n",
    "#         \"Soil_Type35\": \"integer_categorical\",\n",
    "#         \"Soil_Type36\": \"integer_categorical\",\n",
    "#         \"Soil_Type37\": \"integer_categorical\",\n",
    "#         \"Soil_Type38\": \"integer_categorical\",\n",
    "#         \"Soil_Type39\": \"integer_categorical\",\n",
    "#         \"Soil_Type40\": \"integer_categorical\",\n",
    "        \n",
    "        \n",
    "#         # Numerical features to normalize\n",
    "#         \"Elevation\": \"float_normalized\",\n",
    "#         \"Aspect\": \"float_normalized\",\n",
    "#         \"Slope\": \"float_normalized\",\n",
    "#         \"Horizontal_Distance_To_Hydrology\": \"float_normalized\",\n",
    "#         \"Vertical_Distance_To_Hydrology \": \"float_normalized\",\n",
    "#         \"Horizontal_Distance_To_Roadways\": \"float_normalized\",\n",
    "#         \"Hillshade_9am\": \"float_normalized\",\n",
    "#         \"Hillshade_Noon\": \"float_normalized\",\n",
    "#         \"Hillshade_3pm\": \"float_normalized\",\n",
    "#         \"Horizontal_Distance_To_Fire_Points\": \"float_normalized\",\n",
    "        \n",
    "#     },\n",
    "    \n",
    "#     output_mode=\"concat\",\n",
    "# )\n",
    "# train_ds_with_no_labels = train_ds.map(lambda x, _: x)\n",
    "# feature_space.adapt(train_ds_with_no_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing data (just for the 10 features, the rest of them are binary)\n",
    "scaler = StandardScaler()\n",
    "X_train=scaler.fit_transform(train_dataframe.iloc[:,:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine normalized features with others\n",
    "X_train = np.concatenate((X_train,train_dataframe.iloc[:,10:].values),axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def normalization(data):\n",
    "    data_scaled= scaler.transform(data.iloc[:,:10])\n",
    "    data=np.concatenate((data_scaled,data.iloc[:,10:].values),axis=1)\n",
    "    \n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_val=normalization(val_dataframe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare labels\n",
    "def to_categorical(data):\n",
    "    data=tf.keras.utils.to_categorical(data)\n",
    "    \n",
    "    return data\n",
    "# making dataset\n",
    "def dataset(x,y):\n",
    "    x=x.astype(np.float32)\n",
    "    y=y.astype(np.float32)\n",
    "    x=torch.from_numpy(x)\n",
    "    y= torch.from_numpy(y)\n",
    "    ds= torch.utils.data.TensorDataset(x,y)\n",
    "    \n",
    "    return ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train= train_dataframe.iloc[:,-1]\n",
    "Y_train =to_categorical(Y_train)\n",
    "Y_val= val_dataframe.iloc[:,-1]\n",
    "Y_val =to_categorical(Y_val)\n",
    "train_ds=dataset(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds=dataset(X_val,Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = torch.utils.data.DataLoader(train_ds, batch_size=128,shuffle=True)\n",
    "val_ds = torch.utils.data.DataLoader(val_ds, batch_size=128,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_relu = nn.Sequential(nn.Linear(55,300),\n",
    "                                         nn.ReLU(),\n",
    "                                        #  nn.Dropout(p=0.1),\n",
    "                                        nn.BatchNorm1d(300),\n",
    "                                        nn.Linear(300,450),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.BatchNorm1d(450),\n",
    "                                        nn.Linear(450,8),\n",
    "                                        nn.Softmax(dim=1)\n",
    "                                         \n",
    "\n",
    "\n",
    "                                         )\n",
    "    def forward(self,x):\n",
    "        x= self.linear_relu(x)\n",
    "        \n",
    "        return x\n",
    "model =network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate = 0.01\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.01)\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"mps\")\n",
    "# model.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss in epoch 1 is 1.2996159743499445 and accuracy is 0.9748122692108154 \n",
      "loss in epoch 2 is 1.2973528973389066 and accuracy is 0.9770874381065369 \n",
      "loss in epoch 3 is 1.2966041514468336 and accuracy is 0.977907657623291 \n",
      "loss in epoch 4 is 1.297108126498113 and accuracy is 0.9773375391960144 \n",
      "loss in epoch 5 is 1.2962955157981113 and accuracy is 0.9781147241592407 \n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    running_loss=0.0\n",
    "    correct=0\n",
    "    for data in  iter(train_ds):\n",
    "        inputs,labels = data\n",
    "        # inputs=inputs.to('mps')\n",
    "        # labels=labels.to(device)\n",
    "        \n",
    "        \n",
    "        \n",
    "        y_pred=model(inputs)\n",
    "        loss = criterion(y_pred,labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss +=loss.item()\n",
    "        correct += y_pred.argmax(1).eq(labels.argmax(1)).sum()\n",
    "   \n",
    "\n",
    "    \n",
    "    alpha = len(train_ds.dataset)/128\n",
    "    train_loss = running_loss/alpha\n",
    "    accuracy = correct /len(train_ds.dataset)\n",
    "\n",
    "    print(f'loss in epoch {epoch+1} is {train_loss} and accuracy is {accuracy} ')\n",
    "    running_loss=0\n",
    "    correct=0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test (dataloader):\n",
    "    running_loss=0.0\n",
    "    correct=0\n",
    "    with torch.no_grad():\n",
    "        for x,y in dataloader:\n",
    "            pred= model(x)\n",
    "            running_loss += criterion(pred,y).item()\n",
    "            correct += pred.argmax(1).eq(y.argmax(1)).sum()\n",
    "    accuracy = correct /len(dataloader.dataset) \n",
    "    loss_test=running_loss/  len(dataloader)     \n",
    "    print(f'loss  is {loss_test} and accuracy is {accuracy} ')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss  is 1.2956764781655439 and accuracy is 0.9782922267913818 \n"
     ]
    }
   ],
   "source": [
    "test(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss  is 1.295442274751117 and accuracy is 0.9785459637641907 \n"
     ]
    }
   ],
   "source": [
    "X_test = normalization(test_dataframe)\n",
    "Y_test= test_dataframe.iloc[:,-1]\n",
    "Y_test =to_categorical(Y_test)\n",
    "test_ds=dataset(X_test,Y_test)\n",
    "test_ds = torch.utils.data.DataLoader(test_ds, batch_size=128,shuffle=False)\n",
    "test(test_ds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
